{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a930d815-0558-4e04-823c-932b2122b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "sns.set()\n",
    "\n",
    "# 그래프 기본 설정\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 전처리 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차 검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 모델의 최적의 하이퍼 파라미터를 찾기 위한 도구\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 학습 모델 저장을 위한 라이브러리\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2d4120-7efc-4d4a-86f9-115c3b4d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_parquet('train_12.parquet')\n",
    "y_df = pd.read_parquet('segment_12.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19561485-6e2b-4a5e-b936-9619c6616996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(X_df, y_df, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f41b506-67d2-4a59-ac82-0b72aa230381",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['기준년월', 'ID']\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bdcc72-1357-4e36-837e-28d869e1e143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이용금액_R3M_신용체크</th>\n",
       "      <th>입회경과개월수_신용</th>\n",
       "      <th>_1순위카드이용금액</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>이용거절여부_카드론</th>\n",
       "      <th>최종카드발급경과월</th>\n",
       "      <th>이용금액_R3M_신용</th>\n",
       "      <th>_1순위카드이용건수</th>\n",
       "      <th>이용금액_R3M_체크</th>\n",
       "      <th>직장시도명</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "      <th>잔액_한도소진율</th>\n",
       "      <th>증감율_카드론_분기</th>\n",
       "      <th>증감율_일시불_분기</th>\n",
       "      <th>증감율_체크_분기</th>\n",
       "      <th>증감율_카드론_전월</th>\n",
       "      <th>변동률_RV평잔</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-454</td>\n",
       "      <td>71</td>\n",
       "      <td>3027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-454</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.878859</td>\n",
       "      <td>1.398627</td>\n",
       "      <td>3.407027</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>-0.609648</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7089</td>\n",
       "      <td>16</td>\n",
       "      <td>7259</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7089</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.196375</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>-0.597498</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.214949</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27336</td>\n",
       "      <td>128</td>\n",
       "      <td>26968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>27336</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115879</td>\n",
       "      <td>0.187467</td>\n",
       "      <td>-1.198788</td>\n",
       "      <td>4.332080</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>-0.154887</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>-2.839702</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4270</td>\n",
       "      <td>31</td>\n",
       "      <td>4807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4270</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781401</td>\n",
       "      <td>1.282494</td>\n",
       "      <td>6.248569</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.593422</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9385</td>\n",
       "      <td>6</td>\n",
       "      <td>3989</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7387</td>\n",
       "      <td>-2</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.986860</td>\n",
       "      <td>-2.056257</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>4.964378</td>\n",
       "      <td>-0.654283</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>10755</td>\n",
       "      <td>209</td>\n",
       "      <td>5640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>7267</td>\n",
       "      <td>3</td>\n",
       "      <td>3488</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.986860</td>\n",
       "      <td>-1.890821</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.199105</td>\n",
       "      <td>-0.212206</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>27636</td>\n",
       "      <td>17</td>\n",
       "      <td>26357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>27636</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.377071</td>\n",
       "      <td>2.533815</td>\n",
       "      <td>-0.785374</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>-1.552244</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>23187</td>\n",
       "      <td>115</td>\n",
       "      <td>17171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>23187</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.233282</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>-0.211614</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.986860</td>\n",
       "      <td>-1.998546</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.199105</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>21463</td>\n",
       "      <td>7</td>\n",
       "      <td>6984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>21463</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.766153</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.855024</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        이용금액_R3M_신용체크  입회경과개월수_신용  _1순위카드이용금액  회원여부_이용가능_카드론  이용거절여부_카드론  \\\n",
       "0                -454          71        3027              0           0   \n",
       "1                7089          16        7259              1           0   \n",
       "2               27336         128       26968              0           0   \n",
       "3                4270          31        4807              0           0   \n",
       "4                9385           6        3989              1           0   \n",
       "...               ...         ...         ...            ...         ...   \n",
       "399995          10755         209        5640              1           0   \n",
       "399996          27636          17       26357              1           0   \n",
       "399997          23187         115       17171              0           0   \n",
       "399998              0          71           0              1           0   \n",
       "399999          21463           7        6984              0           1   \n",
       "\n",
       "        최종카드발급경과월  이용금액_R3M_신용  _1순위카드이용건수  이용금액_R3M_체크  직장시도명  ...  \\\n",
       "0              27         -454          25            0      9  ...   \n",
       "1              23         7089          31            0      1  ...   \n",
       "2              25        27336          52            0      9  ...   \n",
       "3              22         4270          27            0      8  ...   \n",
       "4              20         7387          -2         1997      4  ...   \n",
       "...           ...          ...         ...          ...    ...  ...   \n",
       "399995         39         7267           3         3488     11  ...   \n",
       "399996         24        27636          38            0     12  ...   \n",
       "399997         18        23187          33            0      9  ...   \n",
       "399998         27            0          -2            0      8  ...   \n",
       "399999         18        21463          -2            0      3  ...   \n",
       "\n",
       "        변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  잔액_한도소진율  증감율_카드론_분기  증감율_일시불_분기  \\\n",
       "0            0.000000   0.878859   1.398627  3.407027    0.143423   -0.609648   \n",
       "1            0.000000   0.000000   0.000000  5.196375    0.143423   -0.597498   \n",
       "2           -0.115879   0.187467  -1.198788  4.332080    0.143423   -0.154887   \n",
       "3            0.000000   0.781401   1.282494  6.248569    0.143423    0.593422   \n",
       "4            0.000000   0.762016   0.986860 -2.056257    0.143423    4.964378   \n",
       "...               ...        ...        ...       ...         ...         ...   \n",
       "399995       0.000000   0.762016   0.986860 -1.890821    0.143423    0.199105   \n",
       "399996       0.000000   1.377071   2.533815 -0.785374    0.143423   -1.552244   \n",
       "399997       0.000000   0.000000   0.000000 -0.233282    0.143423   -0.211614   \n",
       "399998       0.000000   0.762016   0.986860 -1.998546    0.143423    0.199105   \n",
       "399999       0.000000   0.000000   0.000000 -1.766153    0.143423    0.855024   \n",
       "\n",
       "        증감율_체크_분기  증감율_카드론_전월  변동률_RV평잔  Segment  \n",
       "0        0.086480    0.048726  0.321733        D  \n",
       "1        0.086480    0.048726  0.214949        E  \n",
       "2        0.086480    0.048726 -2.839702        C  \n",
       "3        0.086480    0.048726  0.321733        D  \n",
       "4       -0.654283    0.048726  0.321733        E  \n",
       "...           ...         ...       ...      ...  \n",
       "399995  -0.212206    0.048726  0.321733        E  \n",
       "399996   0.086480    0.048726  0.321733        D  \n",
       "399997   0.086480    0.048726  0.321733        C  \n",
       "399998   0.086480    0.048726  0.321733        E  \n",
       "399999   0.086480    0.048726  0.321733        E  \n",
       "\n",
       "[400000 rows x 311 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b20c4a-5e7f-4841-b3be-c6d7dc2e5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 전체 데이터프레임에서 A와 B만 추출\n",
    "df_ab = df[df['Segment'].isin(['A', 'B'])].copy()  # copy()는 경고 방지용\n",
    "\n",
    "# 2. X, y 분리\n",
    "X = df_ab.drop(columns=['Segment'])\n",
    "y = df_ab['Segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a55894-9aee-47bf-ab27-36dbbb65546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898      A\n",
       "5253      A\n",
       "8128      A\n",
       "10808     A\n",
       "14951     A\n",
       "         ..\n",
       "376373    A\n",
       "378479    A\n",
       "390620    B\n",
       "393027    A\n",
       "393888    A\n",
       "Name: Segment, Length: 186, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805c385c-7ace-4298-ae4d-1cdd1672d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 타겟 값 y 인코딩\n",
    "le_y = LabelEncoder()\n",
    "y = le_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc798782-ce7b-476c-b75e-04c7c156759a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898      A\n",
       "5253      A\n",
       "8128      A\n",
       "10808     A\n",
       "14951     A\n",
       "         ..\n",
       "376373    A\n",
       "378479    A\n",
       "390620    B\n",
       "393027    A\n",
       "393888    A\n",
       "Name: Segment, Length: 186, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a724d2-a021-471e-82b2-893c12997806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 스케일링\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5863cde0-5d68-4316-b6d8-b8105e0604c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14608377, -0.81367521,  0.24139448, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.10950553,  0.20512821, -0.35668403, ...,  0.        ,\n",
       "         0.        , -0.2696529 ],\n",
       "       [-1.73719131,  0.28717949, -1.69248122, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.35008308, -1.34700855,  0.76411721, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.1135163 , -0.85470085,  0.01999888, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00556924,  0.21880342,  0.01804699, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa33a39-17ea-4872-ad7e-fcd05d73d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled   = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65bac7a5-3b86-4d08-9efc-782bc61046e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A/B만 남긴 후 y는 반드시 pandas Series 상태 유지\n",
    "df_ab = df[df['Segment'].isin(['A', 'B'])].copy()\n",
    "X = df_ab.drop(columns=['Segment'])\n",
    "y = df_ab['Segment']\n",
    "\n",
    "# 2. train/val 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 스케일링 (결과를 다시 DataFrame으로)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns, index=X_train.index)\n",
    "X_val_scaled   = pd.DataFrame(scaler.transform(X_val), columns=X.columns, index=X_val.index)\n",
    "\n",
    "# 4. 라벨 인코딩 (A → 0, B → 1) → Series로 유지!\n",
    "y_train_enc = (y_train == 'B').astype(int)\n",
    "y_val_enc   = (y_val == 'B').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "193deed4-e8fc-45ea-a209-5a6f9c50799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.61696\n",
      "[1]\tvalidation_0-logloss:0.56757\n",
      "[2]\tvalidation_0-logloss:0.52810\n",
      "[3]\tvalidation_0-logloss:0.48969\n",
      "[4]\tvalidation_0-logloss:0.46249\n",
      "[5]\tvalidation_0-logloss:0.43480\n",
      "[6]\tvalidation_0-logloss:0.41498\n",
      "[7]\tvalidation_0-logloss:0.39942\n",
      "[8]\tvalidation_0-logloss:0.38301\n",
      "[9]\tvalidation_0-logloss:0.36761\n",
      "[10]\tvalidation_0-logloss:0.36242\n",
      "[11]\tvalidation_0-logloss:0.35545\n",
      "[12]\tvalidation_0-logloss:0.35030\n",
      "[13]\tvalidation_0-logloss:0.34262\n",
      "[14]\tvalidation_0-logloss:0.33996\n",
      "[15]\tvalidation_0-logloss:0.33307\n",
      "[16]\tvalidation_0-logloss:0.32724\n",
      "[17]\tvalidation_0-logloss:0.32332\n",
      "[18]\tvalidation_0-logloss:0.32503\n",
      "[19]\tvalidation_0-logloss:0.32261\n",
      "[20]\tvalidation_0-logloss:0.32603\n",
      "[21]\tvalidation_0-logloss:0.32855\n",
      "[22]\tvalidation_0-logloss:0.32830\n",
      "[23]\tvalidation_0-logloss:0.33192\n",
      "[24]\tvalidation_0-logloss:0.32936\n",
      "[25]\tvalidation_0-logloss:0.33037\n",
      "[26]\tvalidation_0-logloss:0.33288\n",
      "[27]\tvalidation_0-logloss:0.33136\n",
      "[28]\tvalidation_0-logloss:0.33395\n",
      "[29]\tvalidation_0-logloss:0.33616\n",
      "[30]\tvalidation_0-logloss:0.33538\n",
      "[31]\tvalidation_0-logloss:0.33503\n",
      "[32]\tvalidation_0-logloss:0.33831\n",
      "[33]\tvalidation_0-logloss:0.34074\n",
      "[34]\tvalidation_0-logloss:0.34034\n",
      "[35]\tvalidation_0-logloss:0.34242\n",
      "[36]\tvalidation_0-logloss:0.34388\n",
      "[37]\tvalidation_0-logloss:0.34274\n",
      "[38]\tvalidation_0-logloss:0.34403\n",
      "[39]\tvalidation_0-logloss:0.34479\n",
      "[40]\tvalidation_0-logloss:0.34425\n",
      "[41]\tvalidation_0-logloss:0.34362\n",
      "[42]\tvalidation_0-logloss:0.34832\n",
      "[43]\tvalidation_0-logloss:0.34713\n",
      "[44]\tvalidation_0-logloss:0.35092\n",
      "[45]\tvalidation_0-logloss:0.35307\n",
      "[46]\tvalidation_0-logloss:0.35733\n",
      "[47]\tvalidation_0-logloss:0.36018\n",
      "[48]\tvalidation_0-logloss:0.35747\n",
      "[49]\tvalidation_0-logloss:0.36089\n",
      "[50]\tvalidation_0-logloss:0.36014\n",
      "[51]\tvalidation_0-logloss:0.36079\n",
      "[52]\tvalidation_0-logloss:0.36220\n",
      "[53]\tvalidation_0-logloss:0.35982\n",
      "[54]\tvalidation_0-logloss:0.35629\n",
      "[55]\tvalidation_0-logloss:0.35653\n",
      "[56]\tvalidation_0-logloss:0.35626\n",
      "[57]\tvalidation_0-logloss:0.35817\n",
      "[58]\tvalidation_0-logloss:0.35924\n",
      "[59]\tvalidation_0-logloss:0.35947\n",
      "[60]\tvalidation_0-logloss:0.35742\n",
      "[61]\tvalidation_0-logloss:0.35804\n",
      "[62]\tvalidation_0-logloss:0.35961\n",
      "[63]\tvalidation_0-logloss:0.36104\n",
      "[64]\tvalidation_0-logloss:0.36132\n",
      "[65]\tvalidation_0-logloss:0.36261\n",
      "[66]\tvalidation_0-logloss:0.36289\n",
      "[67]\tvalidation_0-logloss:0.36500\n",
      "[68]\tvalidation_0-logloss:0.36245\n",
      "[69]\tvalidation_0-logloss:0.36358\n",
      "[70]\tvalidation_0-logloss:0.36567\n",
      "[71]\tvalidation_0-logloss:0.36542\n",
      "[72]\tvalidation_0-logloss:0.36685\n",
      "[73]\tvalidation_0-logloss:0.36452\n",
      "[74]\tvalidation_0-logloss:0.36631\n",
      "[75]\tvalidation_0-logloss:0.36849\n",
      "[76]\tvalidation_0-logloss:0.36906\n",
      "[77]\tvalidation_0-logloss:0.37062\n",
      "[78]\tvalidation_0-logloss:0.36847\n",
      "[79]\tvalidation_0-logloss:0.36992\n",
      "[80]\tvalidation_0-logloss:0.36927\n",
      "[81]\tvalidation_0-logloss:0.37073\n",
      "[82]\tvalidation_0-logloss:0.37400\n",
      "[83]\tvalidation_0-logloss:0.37441\n",
      "[84]\tvalidation_0-logloss:0.37550\n",
      "[85]\tvalidation_0-logloss:0.37688\n",
      "[86]\tvalidation_0-logloss:0.37831\n",
      "[87]\tvalidation_0-logloss:0.37757\n",
      "[88]\tvalidation_0-logloss:0.37866\n",
      "[89]\tvalidation_0-logloss:0.37804\n",
      "[90]\tvalidation_0-logloss:0.37909\n",
      "[91]\tvalidation_0-logloss:0.38047\n",
      "[92]\tvalidation_0-logloss:0.37972\n",
      "[93]\tvalidation_0-logloss:0.38167\n",
      "[94]\tvalidation_0-logloss:0.38011\n",
      "[95]\tvalidation_0-logloss:0.37949\n",
      "[96]\tvalidation_0-logloss:0.37967\n",
      "[97]\tvalidation_0-logloss:0.37939\n",
      "[98]\tvalidation_0-logloss:0.37989\n",
      "[99]\tvalidation_0-logloss:0.37992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    use_label_encoder=False,\n",
    "    scale_pos_weight=33/5,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_enc,\n",
    "          eval_set=[(X_val_scaled, y_val_enc)],\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82c18610-5a84-49e0-86e9-ecd1232d70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 [Cut-off = 0.3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.94      0.94        33\n",
      "           B       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.77      0.77      0.77        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 확률 예측 → B 클래스일 확률\n",
    "y_pred_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# 확률 0.5 기준으로 이진 분류\n",
    "y_pred_thresh = (y_pred_prob > 0.3).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 평가\n",
    "print(\"🔍 [Cut-off = 0.3]\")\n",
    "print(classification_report(y_val_enc, y_pred_thresh, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d5775-1586-47fb-b513-35049f01eb3a",
   "metadata": {},
   "source": [
    "### LightGBM 학습 & 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d739da-276e-479f-981b-cf3118c74193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 클래스 비율 계산\n",
    "scale_pos_weight = y_train_enc.value_counts()[0] / y_train_enc.value_counts()[1]\n",
    "\n",
    "lgb_model = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    class_weight='balanced',         # 자동으로 클래스 비율 적용\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 예측\n",
    "y_pred_prob_lgb = lgb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred_lgb = (y_pred_prob_lgb > 0.3).astype(int)\n",
    "\n",
    "print(\"🔍 [LightGBM Classification Report]\")\n",
    "print(classification_report(y_val_enc, y_pred_lgb, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb6953-3bf3-4241-90ca-09615d7d4718",
   "metadata": {},
   "source": [
    "- class_weight 를 변경해서 돌려본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92ab5fa5-e3da-43f8-8e79-ac2457239c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19, number of negative: 129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5330\n",
      "[LightGBM] [Info] Number of data points in the train set: 148, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492925 -> initscore=-0.028304\n",
      "[LightGBM] [Info] Start training from score -0.028304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "🔍 [LightGBM Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.91      0.94      0.93        33\n",
      "           B       0.50      0.40      0.44         5\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.71      0.67      0.68        38\n",
      "weighted avg       0.86      0.87      0.86        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 클래스 비율 계산\n",
    "scale_pos_weight = y_train_enc.value_counts()[0] / y_train_enc.value_counts()[1]\n",
    "\n",
    "# 수동 class weight 방식 (dict로 지정!)\n",
    "lgb_model = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    class_weight={0: 1, 1: 33/5},   # A=0, B=1 에 가중치 부여\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 예측\n",
    "y_pred_prob_lgb = lgb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred_lgb = (y_pred_prob_lgb > 0.3).astype(int)\n",
    "\n",
    "print(\"🔍 [LightGBM Classification Report]\")\n",
    "print(classification_report(y_val_enc, y_pred_lgb, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc734dc-f15c-415d-a9bd-d0d9facc289f",
   "metadata": {},
   "source": [
    "### CatBoost 학습 & 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baa6271f-4566-4461-86d3-26720190ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl.metadata (1.4 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd5f133d-e839-4df0-a533-bc525549e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 [CatBoost Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.94      0.94        33\n",
      "           B       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.77      0.77      0.77        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 클래스 비율: A = 0, B = 1\n",
    "scale_pos_weight = y_train_enc.value_counts()[0] / y_train_enc.value_counts()[1]\n",
    "\n",
    "# 모델 정의\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    depth=4,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='Logloss',\n",
    "    class_weights=[1, scale_pos_weight],  # A:1, B:6.6 정도\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "cat_model.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 예측\n",
    "y_pred_prob_cat = cat_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred_cat = (y_pred_prob_cat > 0.3).astype(int)\n",
    "\n",
    "# 평가 출력\n",
    "print(\"🔍 [CatBoost Classification Report]\")\n",
    "print(classification_report(y_val_enc, y_pred_cat, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3aec87-7ec3-47f2-90d3-4de80b4cf677",
   "metadata": {},
   "source": [
    "- CatBoost Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07859f22-7daa-493f-a134-b8a317135566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56b674b5-934f-46ad-a230-82664c1305f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 11:49:50,957] A new study created in memory with name: no-name-e3899d86-c695-44b4-9089-cc6ac30ccb4b\n",
      "[I 2025-07-10 11:49:51,409] Trial 0 finished with value: 0.6 and parameters: {'iterations': 871, 'depth': 9, 'learning_rate': 0.13491814489971662, 'l2_leaf_reg': 2.1952464492338857, 'border_count': 99}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-07-10 11:49:52,637] Trial 1 finished with value: 0.6666666666666666 and parameters: {'iterations': 870, 'depth': 10, 'learning_rate': 0.14703567318560587, 'l2_leaf_reg': 8.47204460231985, 'border_count': 66}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:53,327] Trial 2 finished with value: 0.6 and parameters: {'iterations': 428, 'depth': 10, 'learning_rate': 0.08980957398911946, 'l2_leaf_reg': 2.3268329503099667, 'border_count': 71}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:53,372] Trial 3 finished with value: 0.6666666666666666 and parameters: {'iterations': 562, 'depth': 4, 'learning_rate': 0.20287049247385763, 'l2_leaf_reg': 8.410073625178432, 'border_count': 83}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:53,429] Trial 4 finished with value: 0.5 and parameters: {'iterations': 252, 'depth': 5, 'learning_rate': 0.05828353324884175, 'l2_leaf_reg': 7.811066078335245, 'border_count': 68}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:53,565] Trial 5 finished with value: 0.4 and parameters: {'iterations': 681, 'depth': 7, 'learning_rate': 0.13557610258266362, 'l2_leaf_reg': 8.160474345222985, 'border_count': 117}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:53,807] Trial 6 finished with value: 0.6666666666666666 and parameters: {'iterations': 276, 'depth': 8, 'learning_rate': 0.2091242500518034, 'l2_leaf_reg': 9.692386722419736, 'border_count': 112}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:54,151] Trial 7 finished with value: 0.4 and parameters: {'iterations': 381, 'depth': 9, 'learning_rate': 0.026707413859954898, 'l2_leaf_reg': 6.858407314968996, 'border_count': 42}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,370] Trial 8 finished with value: 0.5 and parameters: {'iterations': 612, 'depth': 10, 'learning_rate': 0.2258067305557298, 'l2_leaf_reg': 7.246999438745045, 'border_count': 125}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,462] Trial 9 finished with value: 0.4444444444444444 and parameters: {'iterations': 233, 'depth': 6, 'learning_rate': 0.2010949882120075, 'l2_leaf_reg': 3.693733400577484, 'border_count': 94}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,736] Trial 10 finished with value: 0.4444444444444444 and parameters: {'iterations': 964, 'depth': 7, 'learning_rate': 0.29757703223559173, 'l2_leaf_reg': 4.96812581253058, 'border_count': 45}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,797] Trial 11 finished with value: 0.6 and parameters: {'iterations': 791, 'depth': 4, 'learning_rate': 0.17235880362391137, 'l2_leaf_reg': 9.622469710000919, 'border_count': 60}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,848] Trial 12 finished with value: 0.6 and parameters: {'iterations': 536, 'depth': 4, 'learning_rate': 0.26468417364757496, 'l2_leaf_reg': 5.678911330701148, 'border_count': 84}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:55,975] Trial 13 finished with value: 0.6 and parameters: {'iterations': 113, 'depth': 6, 'learning_rate': 0.1569476478787559, 'l2_leaf_reg': 8.974879560221114, 'border_count': 55}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:56,257] Trial 14 finished with value: 0.6666666666666666 and parameters: {'iterations': 731, 'depth': 8, 'learning_rate': 0.10814248919836493, 'l2_leaf_reg': 6.1710369571538815, 'border_count': 82}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:56,328] Trial 15 finished with value: 0.42857142857142855 and parameters: {'iterations': 962, 'depth': 5, 'learning_rate': 0.24403094007503456, 'l2_leaf_reg': 8.494085587007948, 'border_count': 93}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:56,624] Trial 16 finished with value: 0.6666666666666666 and parameters: {'iterations': 540, 'depth': 8, 'learning_rate': 0.180432259058579, 'l2_leaf_reg': 4.666099726728486, 'border_count': 73}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:56,732] Trial 17 finished with value: 0.6666666666666666 and parameters: {'iterations': 827, 'depth': 6, 'learning_rate': 0.09801072240677006, 'l2_leaf_reg': 1.0475149347236323, 'border_count': 53}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:56,834] Trial 18 finished with value: 0.6 and parameters: {'iterations': 462, 'depth': 5, 'learning_rate': 0.26541182319983025, 'l2_leaf_reg': 6.766795416888146, 'border_count': 103}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:57,138] Trial 19 finished with value: 0.6666666666666666 and parameters: {'iterations': 670, 'depth': 9, 'learning_rate': 0.13204912021480167, 'l2_leaf_reg': 7.683727148937008, 'border_count': 34}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:57,688] Trial 20 finished with value: 0.5 and parameters: {'iterations': 902, 'depth': 10, 'learning_rate': 0.19573252488374152, 'l2_leaf_reg': 9.34052304334487, 'border_count': 64}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:57,963] Trial 21 finished with value: 0.6 and parameters: {'iterations': 329, 'depth': 8, 'learning_rate': 0.2202652517092621, 'l2_leaf_reg': 9.76290118304088, 'border_count': 108}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:58,420] Trial 22 finished with value: 0.6 and parameters: {'iterations': 104, 'depth': 9, 'learning_rate': 0.20982551772076508, 'l2_leaf_reg': 9.985575658902029, 'border_count': 117}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:58,842] Trial 23 finished with value: 0.6 and parameters: {'iterations': 223, 'depth': 8, 'learning_rate': 0.16733093202777818, 'l2_leaf_reg': 8.82923182972398, 'border_count': 86}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:49:58,967] Trial 24 finished with value: 0.5454545454545454 and parameters: {'iterations': 598, 'depth': 7, 'learning_rate': 0.24244746912134707, 'l2_leaf_reg': 8.454550485621748, 'border_count': 75}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:50:00,420] Trial 25 finished with value: 0.5 and parameters: {'iterations': 465, 'depth': 10, 'learning_rate': 0.17933782692513558, 'l2_leaf_reg': 9.01030477484171, 'border_count': 127}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:50:00,539] Trial 26 finished with value: 0.6 and parameters: {'iterations': 314, 'depth': 6, 'learning_rate': 0.15065975306587867, 'l2_leaf_reg': 7.410610259889803, 'border_count': 90}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:50:00,695] Trial 27 finished with value: 0.4444444444444444 and parameters: {'iterations': 803, 'depth': 7, 'learning_rate': 0.29631917761958615, 'l2_leaf_reg': 6.3888961683967, 'border_count': 77}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:50:00,770] Trial 28 finished with value: 0.6666666666666666 and parameters: {'iterations': 188, 'depth': 4, 'learning_rate': 0.1909531090531855, 'l2_leaf_reg': 8.263543944450497, 'border_count': 113}. Best is trial 1 with value: 0.6666666666666666.\n",
      "[I 2025-07-10 11:50:01,509] Trial 29 finished with value: 0.6 and parameters: {'iterations': 904, 'depth': 9, 'learning_rate': 0.11704528985136767, 'l2_leaf_reg': 9.373952281417207, 'border_count': 98}. Best is trial 1 with value: 0.6666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'iterations': 870, 'depth': 10, 'learning_rate': 0.14703567318560587, 'l2_leaf_reg': 8.47204460231985, 'border_count': 66}\n",
      "🎯 Best F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# objective function\n",
    "def objective(trial):\n",
    "    # 튜닝할 하이퍼파라미터\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 128),\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"class_weights\": [1.0, 6.6],  # A:1, B:6.6 (불균형 반영)\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # 학습 (주의: 내부 검증용 데이터 사용)\n",
    "    model.fit(X_train_scaled, y_train_enc, eval_set=(X_val_scaled, y_val_enc), early_stopping_rounds=30, verbose=0)\n",
    "\n",
    "    # 예측 및 평가\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    score = f1_score(y_val_enc, y_pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "# study 생성 및 최적화\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)  # 시도 횟수는 자유롭게 늘려도 돼\n",
    "\n",
    "# 결과 출력\n",
    "print(\"✅ Best Params:\", study.best_params)\n",
    "print(\"🎯 Best F1 Score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9df0d2e5-f9cc-43bd-a366-34d04a80128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [CatBoost Final Model Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.91      0.97      0.94        33\n",
      "           B       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.79      0.68      0.72        38\n",
      "weighted avg       0.88      0.89      0.88        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Best Params로 모델 구성\n",
    "best_params = {\n",
    "    'iterations': 870,\n",
    "    'depth': 10,\n",
    "    'learning_rate': 0.147,\n",
    "    'l2_leaf_reg': 8.472,\n",
    "    'border_count': 66,\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'F1',\n",
    "    'class_weights': [1.0, 6.6]  # A:1, B:6.6\n",
    "}\n",
    "\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = final_model.predict(X_val_scaled)\n",
    "print(\"✅ [CatBoost Final Model Evaluation]\")\n",
    "print(classification_report(y_val_enc, y_pred, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fa210d4-410f-4d2d-b736-5f6a954d50be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segment\n",
       "0    33\n",
       "1     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_enc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09ca88-0c4e-458f-895d-4a7f010a1295",
   "metadata": {},
   "source": [
    "### SMOTE 적용한 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7acc0676-c0dd-43af-8653-58285def8fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.12/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aeb96acd-e545-4ea3-ac3b-741213d1af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 클래스 비율 (SMOTE 적용 후)\n",
      "Segment\n",
      "0    129\n",
      "1    129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE 적용 (A=0, B=1 인코딩 상태 유지)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_enc)\n",
    "\n",
    "print(\"✅ 클래스 비율 (SMOTE 적용 후)\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82fc8731-1d58-4386-ae68-a04877b8fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [CatBoost + SMOTE Final Evaluation]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.97      0.96        33\n",
      "           B       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.85      0.78      0.81        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 튜닝된 파라미터 적용\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=870,\n",
    "    depth=10,\n",
    "    learning_rate=0.147,\n",
    "    l2_leaf_reg=8.47,\n",
    "    border_count=66,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 학습\n",
    "cb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 예측\n",
    "y_pred_prob = cb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred = (y_pred_prob > 0.3).astype(int)  # threshold 0.3\n",
    "\n",
    "# 평가\n",
    "print(\"✅ [CatBoost + SMOTE Final Evaluation]\")\n",
    "print(classification_report(y_val_enc, y_pred, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25485ed5-abd9-49ad-b635-1a3886bde7f9",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cdaee8a-06fa-4b52-8f20-5f6fec16f359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19, number of negative: 129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5330\n",
      "[LightGBM] [Info] Number of data points in the train set: 148, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492925 -> initscore=-0.028304\n",
      "[LightGBM] [Info] Start training from score -0.028304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "🔍 [VotingClassifier A vs B Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.91      0.97      0.94        33\n",
      "           B       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.79      0.68      0.72        38\n",
      "weighted avg       0.88      0.89      0.88        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 모델 정의 (튜닝 결과 반영)\n",
    "xgb_clf = XGBClassifier(scale_pos_weight=6.6, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "lgb_clf = LGBMClassifier(class_weight={0: 1, 1: 6.6}, random_state=42)\n",
    "\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=870,\n",
    "    depth=10,\n",
    "    learning_rate=0.147,\n",
    "    l2_leaf_reg=8.47,\n",
    "    border_count=66,\n",
    "    class_weights=[1, 6.6],\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. VotingClassifier 구성 (soft voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_clf),\n",
    "        ('lgb', lgb_clf),\n",
    "        ('cat', cat_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 3. 모델 학습\n",
    "voting_clf.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 4. 예측\n",
    "y_pred_vote = voting_clf.predict(X_val_scaled)\n",
    "\n",
    "# 5. 평가\n",
    "print(\"🔍 [VotingClassifier A vs B Classification Report]\")\n",
    "print(classification_report(y_val_enc, y_pred_vote, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6857b-5d4b-4fc7-b513-b05a2811fffa",
   "metadata": {},
   "source": [
    "### Voting threshold 튜닝 (여러 threshold를 loop 돌려서 최적의 threshold 찾음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb89c1f9-85ee-47d9-ac60-a9b136fac56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19, number of negative: 129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5330\n",
      "[LightGBM] [Info] Number of data points in the train set: 148, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492925 -> initscore=-0.028304\n",
      "[LightGBM] [Info] Start training from score -0.028304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "✅ Best threshold: 0.24\n",
      "✅ Best f1-score: 0.6000\n",
      "\n",
      "📊 [VotingClassifier Threshold = 0.24]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.94      0.94        33\n",
      "           B       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.77      0.77      0.77        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 모델 정의 (튜닝 결과 반영)\n",
    "xgb_clf = XGBClassifier(scale_pos_weight=6.6, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "lgb_clf = LGBMClassifier(class_weight={0: 1, 1: 6.6}, random_state=42)\n",
    "\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=870,\n",
    "    depth=10,\n",
    "    learning_rate=0.147,\n",
    "    l2_leaf_reg=8.47,\n",
    "    border_count=66,\n",
    "    class_weights=[1, 6.6],\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. VotingClassifier 구성 (soft voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_clf),\n",
    "        ('lgb', lgb_clf),\n",
    "        ('cat', cat_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 3. 모델 학습\n",
    "voting_clf.fit(X_train_scaled, y_train_enc)\n",
    "\n",
    "# 4. 예측\n",
    "# 4-1. B 클래스 확률 추출\n",
    "y_proba = voting_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# 4-2. 원하는 threshold 설정\n",
    "thresholds = np.arange(0.1, 0.91, 0.01)  # 0.1부터 0.9까지 0.01 간격으로\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "\n",
    "y_pred_probs = voting_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_pred_probs > threshold).astype(int)\n",
    "    f1 = f1_score(y_val_enc, y_pred)\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"✅ Best threshold: {best_threshold:.2f}\")\n",
    "print(f\"✅ Best f1-score: {best_f1:.4f}\")\n",
    "\n",
    "# 4-3. 평가\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_final = (y_pred_probs > best_threshold).astype(int)\n",
    "\n",
    "print(f\"\\n📊 [VotingClassifier Threshold = {best_threshold:.2f}]\")\n",
    "print(classification_report(y_val_enc, y_pred_final, target_names=['A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bf58d02-8f3a-4bd9-98b4-433aa92fdc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(y_pred_probs, bins=20, kde=True)\n",
    "plt.axvline(0.24, color='r', linestyle='--', label='Best Threshold')\n",
    "plt.title('Prediction Probabilities')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39921a33-a069-4cbe-8464-6f560f040622",
   "metadata": {},
   "source": [
    "### CatBoost 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "672282f3-a293-4d1f-9641-f7095838658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('AB_catboost.dat', 'wb') as f:\n",
    "    pickle.dump(cb_model, f)\n",
    "\n",
    "with open('AB_catboost_scaler.dat', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4c78f320-5499-41f4-950c-5e511bbe9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AB_LabelEncoder.dat', 'wb') as f:\n",
    "    pickle.dump(le_y, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
