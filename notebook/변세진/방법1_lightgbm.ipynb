{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1cb1066-552c-48aa-a550-9fb9f8dcb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "sns.set()\n",
    "\n",
    "# 그래프 기본 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 전처리 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차 검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 모델의 최적의 하이퍼 파라미터를 찾기 위한 도구\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 학습 모델 저장을 위한 라이브러리\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de121bf4-83dc-4468-8892-754413a0b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet('train_all_high_corr.parquet')\n",
    "df2 = pd.read_parquet('train_segment.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a603980-c3cd-40ab-88bc-22aa285b6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2['Segment']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48afed8-0c29-4894-ab47-81550197d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089d3a88-aa57-471e-8606-4abe6de5124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " Segment\n",
      "E    0.800855\n",
      "D    0.145518\n",
      "C    0.053163\n",
      "A    0.000405\n",
      "B    0.000060\n",
      "Name: proportion, dtype: float64\n",
      "Val   class distribution:\n",
      " Segment\n",
      "E    0.800856\n",
      "D    0.145517\n",
      "C    0.053163\n",
      "A    0.000404\n",
      "B    0.000060\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 0. X, y 분리\n",
    "#─────────────────────────────────────────────\n",
    "X = df3.drop(columns=['Segment'])\n",
    "y = df3['Segment']\n",
    "\n",
    "#─────────────────────────────────────────────\n",
    "# 1. 학습/검증 세트로 먼저 나누기 (Stratified)\n",
    "#─────────────────────────────────────────────\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,            # 80 : 20\n",
    "    stratify=y,               # 클래스 비율 유지\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print('Train class distribution:\\n', y_train.value_counts(normalize=True))\n",
    "print('Val   class distribution:\\n', y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587f0bc0-343a-47c7-a202-fce99871e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 세트를 두 개 그룹으로 분할\n",
    "#─────────────────────────────────────────────\n",
    "group_AB  = ['A', 'B']\n",
    "group_CDE = ['C', 'D', 'E']\n",
    "\n",
    "# ── A, B\n",
    "mask_AB_train = y_train.isin(group_AB)\n",
    "mask_AB_val   = y_val.isin(group_AB)\n",
    "\n",
    "X_train_AB, y_train_AB = X_train[mask_AB_train], y_train[mask_AB_train]\n",
    "X_val_AB,   y_val_AB   = X_val[mask_AB_val],   y_val[mask_AB_val]\n",
    "\n",
    "# ── C, D, E\n",
    "mask_CDE_train = y_train.isin(group_CDE)\n",
    "mask_CDE_val   = y_val.isin(group_CDE)\n",
    "\n",
    "X_train_CDE, y_train_CDE = X_train[mask_CDE_train], y_train[mask_CDE_train]\n",
    "X_val_CDE,   y_val_CDE   = X_val[mask_CDE_val],   y_val[mask_CDE_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c01a17-6a15-4aa3-8e01-98394e50e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 115, number of negative: 778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9701\n",
      "[LightGBM] [Info] Number of data points in the train set: 893, number of used features: 85\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16131\n",
      "[LightGBM] [Info] Number of data points in the train set: 1919107, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "── Group AB ──\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.99      1.00      1.00       194\n",
      "           B       1.00      0.97      0.98        29\n",
      "\n",
      "    accuracy                           1.00       223\n",
      "   macro avg       1.00      0.98      0.99       223\n",
      "weighted avg       1.00      1.00      1.00       223\n",
      "\n",
      "[[194   0]\n",
      " [  1  28]]\n",
      "\n",
      "── Group CDE ──\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.61      0.83      0.70     25518\n",
      "           D       0.53      0.77      0.63     69848\n",
      "           E       0.98      0.87      0.92    384411\n",
      "\n",
      "    accuracy                           0.86    479777\n",
      "   macro avg       0.70      0.83      0.75    479777\n",
      "weighted avg       0.89      0.86      0.87    479777\n",
      "\n",
      "[[ 21252   3714    552]\n",
      " [  9057  53754   7037]\n",
      " [  4766  44199 335446]]\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────\n",
    "# 0. 라이브러리\n",
    "# ──────────────────────────────────────\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# 1. A, B 모델 (Binary)\n",
    "# ──────────────────────────────────────\n",
    "le_ab = LabelEncoder()\n",
    "y_train_AB_enc = le_ab.fit_transform(y_train_AB)   # 'A','B' → 0,1\n",
    "y_val_AB_enc   = le_ab.transform(y_val_AB)\n",
    "\n",
    "model_AB = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    class_weight='balanced',   # 자동으로 소수 클래스에 가중치\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_AB.fit(\n",
    "    X_train_AB, y_train_AB_enc,\n",
    "    eval_set=[(X_val_AB, y_val_AB_enc)],\n",
    "    eval_metric='binary_logloss',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# 2. C, D, E 모델 (Multi-class)\n",
    "# ──────────────────────────────────────\n",
    "le_cde = LabelEncoder()\n",
    "y_train_CDE_enc = le_cde.fit_transform(y_train_CDE)   # 'C','D','E' → 0,1,2\n",
    "y_val_CDE_enc   = le_cde.transform(y_val_CDE)\n",
    "\n",
    "model_CDE = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    class_weight='balanced',\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_CDE.fit(\n",
    "    X_train_CDE, y_train_CDE_enc,\n",
    "    eval_set=[(X_val_CDE, y_val_CDE_enc)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "# 3. 검증 세트 성능 확인\n",
    "# ──────────────────────────────────────\n",
    "print(\"── Group AB ──\")\n",
    "y_pred_AB = le_ab.inverse_transform(model_AB.predict(X_val_AB))\n",
    "print(classification_report(y_val_AB, y_pred_AB))\n",
    "print(confusion_matrix(y_val_AB, y_pred_AB))\n",
    "\n",
    "print(\"\\n── Group CDE ──\")\n",
    "y_pred_CDE = le_cde.inverse_transform(model_CDE.predict(X_val_CDE))\n",
    "print(classification_report(y_val_CDE, y_pred_CDE))\n",
    "print(confusion_matrix(y_val_CDE, y_pred_CDE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f9391-b3fb-4a9d-85fd-983a9a31d456",
   "metadata": {},
   "source": [
    "### C,D,E 모델 (SMOTE + 가중치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3252b616-bef1-4d08-b43f-9e871e18d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.322415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16666\n",
      "[LightGBM] [Info] Number of data points in the train set: 4305393, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score -1.400088\n",
      "[LightGBM] [Info] Start training from score -0.483797\n",
      "[LightGBM] [Info] Start training from score -1.987874\n",
      "\n",
      "── CDE (SMOTE + 가중치) ──\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.83      0.73      0.77     25518\n",
      "           D       0.52      0.89      0.65     69848\n",
      "           E       0.98      0.86      0.92    384411\n",
      "\n",
      "    accuracy                           0.86    479777\n",
      "   macro avg       0.78      0.83      0.78    479777\n",
      "weighted avg       0.91      0.86      0.87    479777\n",
      "\n",
      "[[ 18589   6314    615]\n",
      " [  2185  62263   5400]\n",
      " [  1701  51931 330779]]\n"
     ]
    }
   ],
   "source": [
    "# 0) 준비\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 숫자 라벨 매핑\n",
    "idx_C, idx_D, idx_E = le_cde.transform(['C','D','E'])   # 예: 0,1,2\n",
    "n_E = (y_train_CDE_enc == idx_E).sum()                  # 다수 클래스(E) 개수\n",
    "target_n = int(n_E * 0.9)                               # E의 90 %까지 증폭\n",
    "\n",
    "# 1) SMOTE : C·D 를 target_n 개수까지 오버샘플링\n",
    "sm = SMOTE(\n",
    "    sampling_strategy={idx_C: target_n, idx_D: target_n},\n",
    "    random_state=42, k_neighbors=5\n",
    ")\n",
    "X_res, y_res = sm.fit_resample(X_train_CDE, y_train_CDE_enc)\n",
    "\n",
    "# 2) 클래스 가중치 : D 쪽을 한 번 더 강조\n",
    "cw = {idx_C: 1.0, idx_D: 2.5, idx_E: 0.5}\n",
    "\n",
    "model_CDE_tuned = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    class_weight=cw,\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.04,\n",
    "    num_leaves=95,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_CDE_tuned.fit(\n",
    "    X_res, y_res,\n",
    "    eval_set=[(X_val_CDE, y_val_CDE_enc)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(120, verbose=False)]\n",
    ")\n",
    "\n",
    "print(\"\\n── CDE (SMOTE + 가중치) ──\")\n",
    "pred = model_CDE_tuned.predict(X_val_CDE)\n",
    "print(classification_report(y_val_CDE_enc, pred, target_names=['C','D','E']))\n",
    "print(confusion_matrix(y_val_CDE_enc, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc6094-6b85-45b4-8737-90763fd2fa22",
   "metadata": {},
   "source": [
    "### Optuna 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103fd0c5-e045-4f98-8ced-12713f98388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a123125-9af6-44fb-9c14-7c7ce9be827a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ceaddb9-9524-4594-a8ce-c242024609ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 08:25:47,235] A new study created in memory with name: no-name-30340b20-6242-4206-b403-2f914cb1efc1\n",
      "[I 2025-07-10 08:43:53,851] Trial 0 finished with value: 0.8278086859106778 and parameters: {'lr': 0.0566875982011417, 'leaves': 31, 'mcs': 27, 'ff': 0.880842589464308, 'bf': 0.8034440659430521, 'l2': 1.5931584886576071}. Best is trial 0 with value: 0.8278086859106778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lr': 0.0566875982011417, 'leaves': 31, 'mcs': 27, 'ff': 0.880842589464308, 'bf': 0.8034440659430521, 'l2': 1.5931584886576071}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 3,\n",
    "        \"metric\": \"multi_logloss\",          # ★ 지표 지정\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"lr\", 0.02, 0.15, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"leaves\", 31, 191, step=16),\n",
    "        \"min_child_samples\": trial.suggest_int(\"mcs\", 10, 60),\n",
    "        \"feature_fraction\": trial.suggest_float(\"ff\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bf\", 0.6, 1.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"l2\", 0.0, 5.0),\n",
    "        \"class_weight\": {idx_C:1.0, idx_D:2.0, idx_E:0.5},\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(4, shuffle=True, random_state=42)\n",
    "    f1s = []\n",
    "    for tr_idx, va_idx in cv.split(X_res, y_res):\n",
    "        mdl = lgb.LGBMClassifier(**params, n_estimators=500)\n",
    "        mdl.fit(\n",
    "            X_res.iloc[tr_idx], y_res[tr_idx],\n",
    "            eval_set=[(X_res.iloc[va_idx], y_res[va_idx])],\n",
    "            eval_metric='multi_logloss',            # ★ fit에도 전달 OK\n",
    "            callbacks=[lgb.early_stopping(30, verbose=False)]\n",
    "        )\n",
    "        preds = mdl.predict(X_res.iloc[va_idx])\n",
    "        f1s.append(f1_score(y_res[va_idx], preds, average=\"macro\"))\n",
    "    return np.mean(f1s)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)   # 빠르게 10회만\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90169382-6ae9-4a3b-982b-595d4ac2e9b9",
   "metadata": {},
   "source": [
    "### Optuna로 찾은 최적의 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06404024-a867-434d-aca2-30637acbc6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── CDE 모델 평가 (Optuna 튜닝 적용) ──\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.62      0.84      0.71     25518\n",
      "           D       0.53      0.78      0.63     69848\n",
      "           E       0.98      0.87      0.92    384411\n",
      "\n",
      "    accuracy                           0.86    479777\n",
      "   macro avg       0.71      0.83      0.76    479777\n",
      "weighted avg       0.89      0.86      0.87    479777\n",
      "\n",
      "[[ 21342   3638    538]\n",
      " [  8620  54245   6983]\n",
      " [  4619  43610 336182]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 1. 레이블 인코딩\n",
    "# ───────────────────────────────────────────────\n",
    "le_cde = LabelEncoder()\n",
    "y_train_CDE_enc = le_cde.fit_transform(y_train_CDE)\n",
    "y_val_CDE_enc   = le_cde.transform(y_val_CDE)\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2. 모델 정의 (Optuna 최적 파라미터 적용)\n",
    "# ───────────────────────────────────────────────\n",
    "model_CDE = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    learning_rate=0.0567,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=27,\n",
    "    feature_fraction=0.8808,\n",
    "    bagging_fraction=0.8034,\n",
    "    reg_lambda=1.5931,\n",
    "    class_weight='balanced',\n",
    "    n_estimators=1500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 3. 학습\n",
    "# ───────────────────────────────────────────────\n",
    "model_CDE.fit(\n",
    "    X_train_CDE, y_train_CDE_enc,\n",
    "    eval_set=[(X_val_CDE, y_val_CDE_enc)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 4. 검증 성능 평가\n",
    "# ───────────────────────────────────────────────\n",
    "y_pred_CDE = model_CDE.predict(X_val_CDE)\n",
    "y_pred_CDE_label = le_cde.inverse_transform(y_pred_CDE)\n",
    "\n",
    "print(\"── CDE 모델 평가 (Optuna 튜닝 적용) ──\")\n",
    "print(classification_report(y_val_CDE, y_pred_CDE_label))\n",
    "print(confusion_matrix(y_val_CDE, y_pred_CDE_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c83f39-ce6a-4fe7-bb1a-cc37df04f1d4",
   "metadata": {},
   "source": [
    "### GATE 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70112ab-38d3-4eed-a329-e98e6fc3d295",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. 라벨 준비\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_train_gate \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m y_val_gate   \u001b[38;5;241m=\u001b[39m y_val\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2. 인코딩\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 라벨 준비\n",
    "y_train_gate = y_train.apply(lambda x: 'AB' if x in ['A', 'B'] else 'CDE')\n",
    "y_val_gate   = y_val.apply(lambda x: 'AB' if x in ['A', 'B'] else 'CDE')\n",
    "\n",
    "# 2. 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_gate = LabelEncoder()\n",
    "y_train_gate_enc = le_gate.fit_transform(y_train_gate)  # 'AB'→0, 'CDE'→1 또는 반대일 수 있음\n",
    "y_val_gate_enc   = le_gate.transform(y_val_gate)\n",
    "\n",
    "# 3. LightGBM 분류기\n",
    "import lightgbm as lgb\n",
    "gate_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. 학습\n",
    "gate_model.fit(\n",
    "    X_train, y_train_gate_enc,\n",
    "    eval_set=[(X_val, y_val_gate_enc)],\n",
    "    eval_metric='binary_logloss',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    ")\n",
    "\n",
    "# 5. 확인 (선택)\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_gate = le_gate.inverse_transform(gate_model.predict(X_val))\n",
    "print(\"=== Gate Model 평가 (AB vs CDE) ===\")\n",
    "print(classification_report(y_val_gate, y_pred_gate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9029de-d5fa-4a1b-8bb3-fe4eb2bfe493",
   "metadata": {},
   "source": [
    "### GATE 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7284dbc9-9c3f-4b38-a919-3c62f185b704",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1) 게이트 확률\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m gate_proba \u001b[38;5;241m=\u001b[39m gate_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 클래스 순서 확인 후 AB의 인덱스 가져오기\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ab_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(le_gate\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gate_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) 게이트 확률\n",
    "gate_proba = gate_model.predict_proba(X_val)\n",
    "\n",
    "# 클래스 순서 확인 후 AB의 인덱스 가져오기\n",
    "ab_index = np.where(le_gate.classes_ == 'AB')[0][0]\n",
    "p_ab_gate = gate_proba[:, ab_index]\n",
    "p_cde_gate = 1 - p_ab_gate\n",
    "\n",
    "# 서브모델 확률\n",
    "proba_ab   = model_AB.predict_proba(X_val)\n",
    "proba_cde  = model_CDE.predict_proba(X_val)\n",
    "\n",
    "# 클래스 인덱스 매핑\n",
    "idx_A = le_ab.transform(['A'])[0]\n",
    "idx_B = le_ab.transform(['B'])[0]\n",
    "idx_C = le_cde.transform(['C'])[0]\n",
    "idx_D = le_cde.transform(['D'])[0]\n",
    "idx_E = le_cde.transform(['E'])[0]\n",
    "\n",
    "# 조건부 확률 결합\n",
    "p_final = np.column_stack([\n",
    "    proba_ab[:, idx_A] * p_ab_gate,\n",
    "    proba_ab[:, idx_B] * p_ab_gate,\n",
    "    proba_cde[:, idx_C] * p_cde_gate,\n",
    "    proba_cde[:, idx_D] * p_cde_gate,\n",
    "    proba_cde[:, idx_E] * p_cde_gate\n",
    "])\n",
    "p_final /= p_final.sum(axis=1, keepdims=True)  # 정규화\n",
    "\n",
    "# 예측 & 평가\n",
    "label_order = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "y_pred = label_order[p_final.argmax(axis=1)]\n",
    "\n",
    "print(\"=== 최종 5-클래스 평가 (게이트 + 서브모델) ===\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17e972-2b34-469b-bdbe-f03e8a494604",
   "metadata": {},
   "source": [
    "### 튜닝한 CDE 모델 사용한 GATE 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2ed26cd-bf3a-4511-b279-440059e33e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [최종 평가] 게이트 + 튜닝된 CDE 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.88      0.95      0.91       194\n",
      "           B       0.93      0.93      0.93        29\n",
      "           C       0.83      0.73      0.77     25518\n",
      "           D       0.52      0.89      0.65     69848\n",
      "           E       0.98      0.86      0.92    384411\n",
      "\n",
      "    accuracy                           0.86    480000\n",
      "   macro avg       0.83      0.87      0.84    480000\n",
      "weighted avg       0.91      0.86      0.87    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 튜닝된 CDE 모델 적용\n",
    "model_CDE = model_CDE_tuned  # ★ 중요: 여기서 기존 모델을 튜닝된 걸로 교체!\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1. 확률 가져오기 & 결합\n",
    "# ─────────────────────────────────────────────\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 게이트 확률\n",
    "gate_proba = gate_model.predict_proba(X_val)\n",
    "\n",
    "# 클래스 순서 확인 후 AB의 인덱스 가져오기\n",
    "ab_index = np.where(le_gate.classes_ == 'AB')[0][0]\n",
    "p_ab_gate = gate_proba[:, ab_index]\n",
    "p_cde_gate = 1 - p_ab_gate\n",
    "\n",
    "\n",
    "# 서브모델 확률\n",
    "proba_ab  = model_AB.predict_proba(X_val)           # (n, 2)\n",
    "proba_cde = model_CDE.predict_proba(X_val)          # (n, 3)\n",
    "\n",
    "# 클래스 인덱스 매칭\n",
    "idx_A = le_ab.transform(['A'])[0]\n",
    "idx_B = le_ab.transform(['B'])[0]\n",
    "idx_C = le_cde.transform(['C'])[0]\n",
    "idx_D = le_cde.transform(['D'])[0]\n",
    "idx_E = le_cde.transform(['E'])[0]\n",
    "\n",
    "# 조건부 확률 결합\n",
    "p_final = np.column_stack([\n",
    "    proba_ab[:, idx_A] * p_ab_gate,\n",
    "    proba_ab[:, idx_B] * p_ab_gate,\n",
    "    proba_cde[:, idx_C] * p_cde_gate,\n",
    "    proba_cde[:, idx_D] * p_cde_gate,\n",
    "    proba_cde[:, idx_E] * p_cde_gate\n",
    "])\n",
    "p_final /= p_final.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 최종 예측\n",
    "label_order = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "y_pred = label_order[p_final.argmax(axis=1)]\n",
    "\n",
    "print(\"✅ [최종 평가] 게이트 + 튜닝된 CDE 모델\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337c5f0-454b-4f1f-af24-e78da1dc9365",
   "metadata": {},
   "source": [
    "### C,D 서브모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b526f010-d031-415d-b9e8-c001b9d10414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.05, n_estimators=1000,\n",
       "               objective=&#x27;binary&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.05, n_estimators=1000,\n",
       "               objective=&#x27;binary&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', learning_rate=0.05, n_estimators=1000,\n",
       "               objective='binary', random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 1) C vs D 데이터 추출\n",
    "cd_mask = y_train_CDE.isin(['C', 'D'])\n",
    "X_train_CD = X_train_CDE[cd_mask]\n",
    "y_train_CD = y_train_CDE[cd_mask]\n",
    "\n",
    "# 2) Label 인코딩\n",
    "le_cd = LabelEncoder()\n",
    "y_train_CD_enc = le_cd.fit_transform(y_train_CD)  # 'C'→0, 'D'→1\n",
    "\n",
    "# 3) SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train_CD, y_train_CD_enc)\n",
    "\n",
    "# 4) 모델 학습\n",
    "model_CD = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    class_weight='balanced',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_CD.fit(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40d1e283-6cb5-4edc-94d7-e63c32f70e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최종 5-클래스 평가 (CD 보정 포함) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.88      0.95      0.91       194\n",
      "           B       0.93      0.93      0.93        29\n",
      "           C       0.67      0.72      0.69     25518\n",
      "           D       0.52      0.81      0.63     69848\n",
      "           E       0.98      0.87      0.92    384411\n",
      "\n",
      "    accuracy                           0.86    480000\n",
      "   macro avg       0.79      0.86      0.82    480000\n",
      "weighted avg       0.90      0.86      0.87    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기존 CDE 확률\n",
    "proba_cde = model_CDE.predict_proba(X_val)\n",
    "\n",
    "# 1) 게이트 확률\n",
    "gate_proba = gate_model.predict_proba(X_val)\n",
    "\n",
    "# 클래스 순서 확인 후 AB의 인덱스 가져오기\n",
    "ab_index = np.where(le_gate.classes_ == 'AB')[0][0]\n",
    "p_ab_gate = gate_proba[:, ab_index]\n",
    "p_cde_gate = 1 - p_ab_gate\n",
    "\n",
    "# 기존 서브 확률\n",
    "idx_C = le_cde.transform(['C'])[0]\n",
    "idx_D = le_cde.transform(['D'])[0]\n",
    "idx_E = le_cde.transform(['E'])[0]\n",
    "\n",
    "# C+D 총합 확률\n",
    "p_c_or_d = proba_cde[:, idx_C] + proba_cde[:, idx_D]\n",
    "\n",
    "# CD 서브모델 확률\n",
    "proba_cd = model_CD.predict_proba(X_val)\n",
    "\n",
    "idx_c = le_cd.transform(['C'])[0]\n",
    "idx_d = le_cd.transform(['D'])[0]\n",
    "\n",
    "# C, D 보정 확률\n",
    "p_c_final = p_cde_gate * p_c_or_d * proba_cd[:, idx_c]\n",
    "p_d_final = p_cde_gate * p_c_or_d * proba_cd[:, idx_d]\n",
    "p_e_final = p_cde_gate * proba_cde[:, idx_E]\n",
    "\n",
    "# AB 확률\n",
    "proba_ab = model_AB.predict_proba(X_val)\n",
    "idx_A = le_ab.transform(['A'])[0]\n",
    "idx_B = le_ab.transform(['B'])[0]\n",
    "\n",
    "p_a_final = p_ab_gate * proba_ab[:, idx_A]\n",
    "p_b_final = p_ab_gate * proba_ab[:, idx_B]\n",
    "\n",
    "# 결합\n",
    "p_final = np.column_stack([p_a_final, p_b_final, p_c_final, p_d_final, p_e_final])\n",
    "p_final /= p_final.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 예측\n",
    "label_order = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "y_pred = label_order[p_final.argmax(axis=1)]\n",
    "\n",
    "print(\"=== 최종 5-클래스 평가 (CD 보정 포함) ===\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0b2f84e-bb36-474d-aa89-85f39e0ae8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('방법1/model_AB_lgbm.dat', 'wb') as f:\n",
    "    pickle.dump(model_AB, f)\n",
    "\n",
    "with open('방법1/model_CDE_tuned_lgbm.dat', 'wb') as f:\n",
    "    pickle.dump(model_CDE_tuned, f)\n",
    "\n",
    "with open('방법1/gate_model_lgbm.dat', 'wb') as f:\n",
    "    pickle.dump(gate_model, f)\n",
    "\n",
    "# 레이블 인코더도 저장\n",
    "with open('방법1/label_encoder_AB.dat', 'wb') as f:\n",
    "    pickle.dump(le_ab, f)\n",
    "\n",
    "with open('방법1/label_encoder_CDE.dat', 'wb') as f:\n",
    "    pickle.dump(le_cde, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4906587a-fa98-4297-a473-fb0fc6996a3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_ab \u001b[38;5;241m=\u001b[39m gate_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAB로 분류된 샘플 수:\u001b[39m\u001b[38;5;124m\"\u001b[39m, (p_ab \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCDE로 분류된 샘플 수:\u001b[39m\u001b[38;5;124m\"\u001b[39m, (p_ab \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gate_model' is not defined"
     ]
    }
   ],
   "source": [
    "p_ab = gate_model.predict_proba(X_test)[:, 1]\n",
    "print(\"AB로 분류된 샘플 수:\", (p_ab > 0.5).sum())\n",
    "print(\"CDE로 분류된 샘플 수:\", (p_ab <= 0.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318ece9-4545-4943-ac69-1425bacd9fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
